# -*- coding: utf-8 -*-
"""day4 linear regression

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18ecdcVFqSD-2vG6fMapsPWJT71BOluRs

###Linear regression is a method used to find a straight-line relationship between two thing -- on eyou already know and one you want to predict

represents a straight line in a two-dimensional plane
#y=mx+c

slope (two points)
#m = (y2 - y1) / (x2 - x1)
slope (many points)
#m=(n∑(xy)-∑(xy))/(n∑(x^2)-∑(x^2))
Intercept(c)
#c=ȳ-m* x̄

##m=slope
##c=intercept
----------------------------------------------------------------------------------------------------------------
#polynomial features
##polynomial features are new features creted by taking the og features and raising them to powers(likex^2,x^3,etc),includibg combinations if there are multiple features.
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

hours =[1,2,3,4,5]
scores =[20,30,40,50,60]

X=np.array(hours).reshape(-1,1)
print(X)
Y=np.array(scores)
print(Y)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
hours =[1,2,3,4,5]
scores =[20,30,40,50,60]
x=np.array(hours).reshape(-1,1)
y=np.array(scores)
model=LinearRegression()
model.fit(x,y)

predited=model.predict([[6]])
print(model.predict([[6]]))
print("predicted score for 6 hours of the study",predited[0])

plt.scatter(x,y,color="red",label="actual data")
plt.plot(x,model.predict(x),color="blue",label="best fit line")
plt.xlabel("hours")
plt.ylabel("scores")
plt.title("study hours vs score")
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
data=pd.read_csv('/content/people_data(data1).csv')


data=data[['Age', 'Salary']]

impute=SimpleImputer(strategy='mean')
data_filled=pd.DataFrame(impute.fit_transform(data),columns=['Age','Salary'])


x=data_filled[['Age']]
y=data_filled[['Salary']]


model=LinearRegression()
model.fit(x,y)
predicted_salary=model.predict([[32]])
print(f"predicted salary for age 32:₹{predicted_salary[0][0]:.2f}")

y_pred=model.predict(x)
mse=mean_squared_error(y,y_pred)
r2=r2_score(y,y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"R-squared: {r2:.2f}")

plt.scatter(x,y,color='red',label='actual data')
plt.plot(x,model.predict(x),color='blue',label='best fit line')
plt.xlabel('Age')
plt.ylabel('Salary')
plt.title('Age vs Salary')
plt.grid(True)
plt.show()

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

actual =[3,5,7,9]
predicted=[2.5,4.8,7.2,8.5]

mse=mean_squared_error(actual,predicted)
r2=r2_score(actual,predicted)

print(f"Mean Squared Error: {mse:.3f}")
print(f"R-squared: {r2:.3f}")

x=[[2],[3],[4]]
from sklearn.preprocessing import PolynomialFeatures
poly=PolynomialFeatures(degree=10)
x_poly=poly.fit_transform(x)
print(x_poly)

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_squared_error, r2_score

#sample data: YearsExperiance vs Salary
data=pd.DataFrame({
    "YearsExperiance": [1,2,3,4,5,6,7,8,9,10],
    "Salary": [30000, 35000, 40000, 50000, 60000, 80000, 110000, 150000, 200000, 300000]
})
x=data[["YearsExperiance"]]
y=data["Salary"]

#train linear model
lin_reg=LinearRegression()
lin_reg.fit(x,y)

#predict
y_pred_linear=lin_reg.predict(x)

#convert to polynomial features (degreeb 2 orb 3 usually works well)
poly=PolynomialFeatures(degree=5)
x_poly=poly.fit_transform(x)
print(x_poly)

#train polynomial model
poly_reg=LinearRegression()
poly_reg.fit(x_poly,y)

#predict
y_pred_poly=poly_reg.predict(x_poly)

#plot the data and the prediction line
plt.scatter(x,y,color="green",label="Actual Data") #actual data
plt.plot(x,y_pred_linear,color="blue",label="LinearRegression")
plt.plot(x,y_pred_poly,color="red",label="PolnomialRegression(Degree 2)")
plt.xlabel("Years of Experiance")
plt.ylabel("Salary")
plt.title("Salary Prediction: Linear vs Polynomial")
plt.legend()
# plt.grid(True)
plt.show()

print("Linear R2:", r2_score(y, y_pred_linear))
print("Polynomial R2:", r2_score(y, y_pred_poly))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
dataset=pd.read_csv('/Position_Salaries(poly_dataset).csv')
print(dataset)
x=dataset.iloc[:,1:-1].values
y=dataset.iloc[:,-1].values
from sklearn.linear_model import LinearRegression
lin_reg=LinearRegression()
lin_reg.fit(x,y)